\subsection{Feature Basis}

Notice that in our current basis that we have 13 features, 8 of which
we build off from the paper in AIAA. The natural question then
becomes, how does performance compare. Do we actually gain a lot in
performance or is it worse or the same? We can perform two experiments
to test things out.

~\\
\noindent \textbf{Experiment 1} Using 8 features, compare logistic
regression performance with using 13 features

\begin{enumerate}
\item Maybe easier to cut the extracted features out of the file
  instead of doing the process over again
\item Run the job to group them
\item Create the training file  
\end{enumerate}

\noindent \textbf{Experiment 2} Now do the same thing except add in
clustering. We expect clustering will boost 8 features since that was
happened last time.

